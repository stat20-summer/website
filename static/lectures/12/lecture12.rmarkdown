---
title: "Lecture 12: Generalizations"
institute: "STAT 20 UC Berkeley"
logo: "images/stat20-hex.png"
format: 
  revealjs:
    theme: "../../../assets/stat20.scss"
    slide-number: true
    incremental: true
    menu: false
    title-slide-attributes:
      data-background-image: hex-background.png
      data-background-size: cover  
    progress: false
execute:
  freeze: auto
---


# First Things First

## First Things First

-   Midterm scores (re) released

    -   Left skewed distribution; median of 19 (out of 24)

-   Notify me of clobber policy decision by **Sunday, July 24 at 11:59pm**

-   The final assignment will be *an exam* with a "project" element

    -   Wednesday, August 10 during class

    -   This time around, there will be test corrections

    -   If you complete the criterion (TBD) you will receive an addl. 5 percentage points (max score 100 percent).

. . .

## First Things First

-   R Cheatsheet Extra Credit Assignment now available on Gradescope

    -   Due Thursday, August 11

    -   Functions you will need to have on your cheatsheet to receive full credit can be located at the R Cheatsheet thread on Ed.

. . .

## First Things First

-   Lab 3 grades published

-   Lab 2 grades will be published by **Sunday, July 24 at 11:59pm**.

-   PS3 video solutions will be released soon

. . .

# Recap

# Confidence Intervals

## Confidence Intervals

-   **Confidence intervals** are an inference procedure which outputs a range of values which we expect the population parameter to reside in.

    -   They have an *upper bound* and a *lower bound*

    -   They are centered around a *point estimate*, which is generally the sample statistic you are using to estimate the population parameter

-   Our confidence that the procedure will work (meaning the parameter will lie inside of our interval) is expressed as a percentage 1 − *α*.

    -   You can call this the *confidence level*.

. . .

## Confidence Intervals

-   Example: If *α* = .05, then our confidence that the procedure will work is 1 − .05 = .95= 95 percent.

-   The 95% confidence interval is the most widespread, but it is not a hard and fast rule

    -   You can choose a different number depending on how confident you want to be in your results

. . .

## Confidence Intervals - Computational Method

## Confidence Intervals - Computational Method

> Construct a 1-*α* confidence interval for your parameter.

. . .

1.  Obtain the *sampling* distribution of the *statistic* which you are using as a *point estimate* for the parameter.

2.  Determine *α*. This will depend on the problem specification (or in the real world, on what you would like it to be).

3.  Obtain the *α*th percentile value of the distribution and the 1-*α*th percentile value. This is because our sampling distribution will be symmetric and we need to take *α*/2 percent from either side to account for the total of *α* percent.

. . .

## Confidence Intervals

-   There are multiple avenues we can take to construct a confidence interval.

-   Yesterday, we learned about computational methods; today we will examine mathematical methods.

. . .

# Confidence Intervals - Mathematical Methods

## Confidence Intervals - Mathematical Methods

-   Why might we want to use a mathematical method rather than the more intuitive, data-driven (computational) method we have already seen?

    -   Data-driven methods are not always practical

    -   Mathematical methods are widely applicable and easy to employ when they are applicable

# Mathematical Method 1

## Confidence Intervals - Mathematical Methods

-   To start today's lecture, we will head back to the probability concepts of *expected value* and *variance*.

-   Remember the *Bernoulli distribution*? A *Bernoulli* random variable *X* has the following probability distribution:

. . .

| *x* | *P*(*X*=*x*) |
|-----|--------------|
| 0   | 1 − *p*      |
| 1   | *p*          |

. . .

## Confidence Intervals - Mathematical Methods

-   If the Bernoulli random variable *X* records one trial of an event that either results in a 0 or a 1, how can we work with multiple, independent trials of that event?

-   Enter the Binomial(*n*, *p*) random variable. This random variable records the sum (number of) successes in *n* independent trials of an event.

-   We discussed how to calculate Binomial probabilities in detail last week.

. . .

## Confidence Intervals - Mathematical Methods

-   Now, say we have are estimating a parameter (a proportion *p*) with a statistic which follows the Binomial distribution. Then we *do not have to do any additional work* to find the sampling distribution of our statistic!

. . .

## Confidence Intervals - Mathematical Methods

-   An example when our statistic is \*B**i**n**o**m**i**a\*\*l*(*n*=100,*p\*=0.5):

. . .


```{r, echo = FALSE, message = FALSE}
library(tidyverse)

df <- tibble(y = 0:100,
             p = dbinom(0:100, 100, prob = .5))
ggplot(df, aes(x = y,
               y = p)) +
  geom_col() +
  xlim(qbinom(.001, size = 100, prob = .5), 
       qbinom(.999, size = 100, prob = .5)) +
  labs(title = "Y ~ Binomial(n = 100, p = .5)",
       y = "Probability") +
  theme_light(base_size = 80)

```


. . .

## Confidence Intervals - Mathematical Methods


```{r, echo = FALSE, message = FALSE}

LB <- qbinom(.025, size = 1000, prob = .50)
UB <- qbinom(.975, size = 1000, prob = .50)
df %>%
  mutate(in_body = y < UB & y > LB) %>%
  ggplot(aes(x = y,
             y = p,
             fill = in_body)) +
  geom_col() +
  xlim(qbinom(.001, size = 1000, prob = .50), 
       qbinom(.999, size = 1000, prob = .50)) +
  labs(title = "Y ~ Binomial(n = 100, p = .5)",
       y = "Probability") +
  theme_light(base_size = 80) +
  theme(legend.position = "none")
```


. . .

What values of *Y* contain the middle 95% of the probability distribution?

-   2.5% quantile: 469

-   97.5% quantile: 531

. . .

-   Therefore, our 95% CI for *p̂* is:

    -   (LB,UB)= (469/1000,531/1000) = (.469,.531)

. . .

# Mathematical Method 2

## Confidence Intervals - Mathematical Models

-   Once again, a *Bernoulli* random variable *X* has the following probability distribution:

. . .

| *x* | *P*(*X*=*x*) |
|-----|--------------|
| 0   | 1 − *p*      |
| 1   | *p*          |

. . .

## Confidence Intervals - Mathematical Methods

Exercise:

-   Calculate the expected value and variance of a Bernoulli random variable *X* for a generic *p* (don't plug any number in for *p*).

. . .

## Confidence Intervals - Mathematical Methods

-   If the Bernoulli random variable *X* records one trial of an event that either results in a 0 or a 1, how can we work with multiple, independent trials of that event?

-   Enter the Binomial(*n*, *p*) random variable. This random variable records the sum (number of) successes in *n* independent trials of an event.

. . .

## Confidence Intervals - Mathematical Methods

-   Consider a Binomial random variable *Y*. Under the framework we just discussed, we can write *Y* mathematically as:

*Y* = *X*<sub>1</sub> + *X*<sub>2</sub> + ... + *X*<sub>*n*</sub>

-   Where *X*<sub>1</sub>, *X*<sub>2</sub>, ... , *X*<sub>*n*</sub> are Bernoulli random variables recording the outcome of trial 1, 2, ..., *n*.

. . .

## Confidence Intervals - Mathematical Methods

Exercise:

-   Calculate the expected variance of a Binomial random variable *Y* for a generic *n* and *p*.

-   Hint: Write *Y* in the way we showed last slide and use the rules for expected value and variance we discussed in Week 3.

. . .

## Confidence Intervals - Mathematical Methods

-   In performing the exercises above, we found that the standard deviation of a Binomial random variable is given by the expression $\\sqrt{\\frac{p(1-p)}{n}}$.

-   This gives us a sense of why the width of a confidence interval might narrow as we increase the sample size *n*.

. . .

## Confidence Intervals - Mathematical Methods

-   So if our sample statistic (*point estimate*) follows a Binomial distribution, and we now have some idea of how it varies, can we create a confidence interval using these two components?

-   The answer is *yes*, and we will see this after the break.

# Break

# Confidence Intervals - Mathematical Method 2

## Central Limit Theorem

-   Averages are special quantities in statistics. Proportions are a type of average; an average of 0s and 1s.

-   A *very* important result in statistics, known as the **Central Limit Theorem,** gives the following result, among others (paraphrased from IMS Ch 13):

    > Under certain conditions, the sampling distribution of the sample proportion will be approximated by the Normal distribution.

. . .

## Normal distribution

-   By far the most commonly known probability distribution

-   It is associated with a symmetric, bell-shaped curve.

-   One nice property of the Normal distribution is that its two parameters, *μ* and *σ*, are *exactly* the distribution's mean and standard deviation, respectively.

. . .

## Normal distribution 

-   Put here the empirical rule or (68-95-99.7 rule)

. . .

## Normal distribution 

-   Put here the formula for doing the confidence interval. Point estimate plus approx plus minus 2 standard error

## Confidence Intervals - Mathematical Method

-   Put an example here

# End of Lecture 12

